# ------ Custom function definitions
# - Load all custom functions defined in a separate R-script
source(paste0(path_cust,"0a.CustomFunctions.R"))
# - Compile Delinquency Calculation Functions (CD, MD/DoD)
source(paste0(path_cust,'DelinqM.R'))
# - Compile the TruEnd-suite of evaluation (and auxiliary) functions
source(paste0(path_cust,'TruEnd.R'))
# ------ 1. Preliminaries
# - Confirm prepared datasets are loaded into memory
if (!exists('datCredit_real')) unpack.ffdf(paste0(genPath,"creditdata_final4a"), tempPath)
if (!exists('datExclusions')) unpack.ffdf(paste0(genObjPath,"Exclusions-TruEnd-Enriched"), tempPath)
# - Confidence interval parameter
confLevel <- 0.95
# - Field names
stratifiers <- c("DefaultStatus1_lead_12_max", "Date") # Must at least include target variable used in graphing event rate
targetVar <- "DefaultStatus1_lead_12_max"
currStatusVar <- "DefaultStatus1"
timeVar <- "Date"
# - Subsampling & resampling parameters
smp_size <- 1500000 # fixed size of downsampled set
train_prop <- 0.7 # sampling fraction for resampling scheme
# --- Exclusions: NAs in provided stratifiers
# [DIAGNOSTIC] Account-level and dataset-wide impacts of excluding NAs in target variable,
# purely due to incomplete outcome window
diag.real_subsamp_5a <- datCredit_real[!complete.cases(mget(stratifiers)) & Counter==1, .N] /
datCredit_real[Counter==1, .N] * 100
diag.real_subsamp_5a_abs <- datCredit_real[!complete.cases(mget(stratifiers)), .N]
diag.real_subsamp_5a_rec <-  diag.real_subsamp_5a_abs / datCredit_real[, .N] * 100
# - Conditional exclusion
if (diag.real_subsamp_5a > 0) {
cat("EXCLUSION: Missingness detected in target variable. Prevalence: ", round(diag.real_subsamp_5a,digits=1), "% of accounts (",
round(diag.real_subsamp_5a_rec,digits=1), "% of records).\n")
# - Apply Exclusion (not necessary to mark within dataset any more, given advanced stage of data process at this point)
# NOTE: Double conversion necessary as annoying fix; see https://github.com/Rdatatable/data.table/issues/3745
datCredit_real <- datCredit_real %>% drop_na(all_of(stratifiers)) %>% as_tibble() %>% as.data.table()
# [SANITY CHECK] Treatment success?
check_excl5a <- datCredit_real[!complete.cases(mget(stratifiers)) & Counter == 1, .N] == 0
cat( check_excl5a %?% 'SAFE: Exclusion successfully applied.\n' %:%
'WARNING: Applying Exclusion failed.\n')
# - Measure impact of exclusion using prevalence rate (Default proportion)
classPrior_remainRecs <- datCredit_real[, sum(get(currStatusVar))] / datCredit_real[,.N]
classPrior_Remain_Diff <- diff(c( as.numeric(sub("%", "", datExclusions[.N, ClassPrior_Remain]))/100, classPrior_remainRecs))
# - Create and add exclusion impact to a common table
datExcl <- data.table("Excl_ID"=8, "Reason"="Missingness in status-field (incomplete outcome window)",
"Impact_Account" = diag.real_subsamp_5a, "Impact_Dataset" = diag.real_subsamp_5a_rec,
"Impact_records" = diag.real_subsamp_5a_abs, "Records_Remain" = datCredit_real[,.N],
"Impact_Dataset_Cumul" = percent(diag.real_subsamp_5a_rec/100, accuracy=0.001),
"ClassPrior_Remain" = percent(classPrior_remainRecs, accuracy=0.001),
"classPrior_Remain_Diff" = percent(classPrior_Remain_Diff, accuracy=0.001))
datExclusions <- rbind(datExclusions, datExcl)
# - Store experimental objects | Memory optimisation
pack.ffdf(paste0(genObjPath,"Exclusions-TruEnd-Enriched2"), datExclusions);
}
# ------ 2. Subsampled resampling scheme with 2-way stratified random sampling
# - Preliminaries
smp_perc <- smp_size / ( datCredit_real[complete.cases(mget(stratifiers)), mget(stratifiers)][,.N] ) # Implied sampling fraction for downsampling step
# - Downsample data into a set with a fixed size (using stratified sampling) before implementing resampling scheme
set.seed(1)
datCredit_smp <- datCredit_real %>% drop_na(all_of(stratifiers)) %>% group_by(across(all_of(stratifiers))) %>% slice_sample(prop=smp_perc) %>% as.data.table()
cat( (datCredit_smp[is.na(get(targetVar)), .N] == 0) %?% 'SAFE: No missingness in target variable.\n' %:%
'WARNING: Missingness detected in target variable.\n')
rm(datCredit_real); gc()
# - Save to disk (zip) for quick disk-based retrieval later
pack.ffdf(paste0(genPath, "creditdata_final4b"), datCredit_smp); gc()
# ------ 3. Fuse the input space with the subsampled prepared dataset
# --- Load in main dataset (subsampled)
if (!exists('datCredit_smp')) unpack.ffdf(paste0(genPath,"creditdata_final4b"), tempPath)
# - Confirm if the input space data is loaded into memory
if (!exists('datInput.raw')) unpack.ffdf(paste0(genPath,"creditdata_input1"), tempPath)
# - Find intersection between fields in input space and those perhaps already in the main credit dataset
(overlap_flds <- intersect(colnames(datCredit_smp), colnames(datInput.raw))) # no overlapping fields
# --- Load in main dataset (subsampled)
if (!exists('datCredit_smp')) unpack.ffdf(paste0(genPath,"creditdata_final4b"), tempPath)
# - Confirm if the input space data is loaded into memory
if (!exists('datInput.raw')) unpack.ffdf(paste0(genPath,"creditdata_input1"), tempPath)
# - Confirm if the input space data is loaded into memory
if (!exists('datInput.raw')) unpack.ffdf(paste0(genPath,"creditdata_allinputs"), tempPath)
colnames(datCredit_allInputs)
rm(datCredit_allInputs)
gc()
# - Confirm if the input space data is loaded into memory
if (!exists('datInput.raw')) unpack.ffdf(paste0(genPath,"creditdata_input1"), tempPath)
# - Find intersection between fields in input space and those perhaps already in the main credit dataset
overlap_flds <- intersect(colnames(datCredit_smp), colnames(datInput.raw))
check.fuse1 <- length(overlap_flds) == 0 # FALSE; duplicate columns exists.
cat(check.fuse1 %?% 'SAFE: No overlapping fields in the input space and the main credit dataset' %:%
'WARNING: Overlapping field(s) detected in the input space and the main credit dataset.')
# Conditional reporting
if (check.fuse1 == 0) {cat('NOTE: The following fields overlap: ', overlap_flds,"\n",sep="\t")}
# - Remove any additional variables that are not going to be used
suppressWarnings( datInput.raw[, `:=`(slc_status_final_pred7 = NULL, slc_status_final = NULL,
slc_curing_ind = NULL, datex = NULL)])
# - Format the date in the correct format for merging
datInput.raw[, date := as.Date(date, format="%Y-%m-%d")]
# - Rename the datasets for merging
colnames(datInput.raw)[colnames(datInput.raw) %in% c("date", "acct_no")] <- c("Date", "LoanID")
# - [SANITY CHECK] Check the data grain
check_input1a <- datInput.raw[, list(Freq = .N), by=list(LoanID, Date)][Freq>1, .N]
# - Find intersection between fields in input space and those perhaps already in the main credit dataset
overlap_flds <- intersect(colnames(datCredit_smp), colnames(datInput.raw))
check.input1 <- length(overlap_flds) == 0 # FALSE; duplicate columns exists.
cat(check.input1 %?% 'SAFE: No overlapping fields in the input space and the main credit dataset' %:%
'WARNING: Overlapping field(s) detected in the input space and the main credit dataset.')
# Conditional reporting
if (check.input1 == 0) {cat('NOTE: The following fields overlap: ', overlap_flds,"\n",sep="\t")}
overlap_flds
# - Remove any additional variables that are not going to be used
suppressWarnings( datInput.raw[, `:=`(slc_status_final_pred7 = NULL, slc_status_final = NULL,
slc_curing_ind = NULL, datex = NULL)])
colnames(datInput.raw)
colnames(datCredit_smp)
# - [SANITY CHECK] Check the data grain
check_input2a <- datInput.raw[, list(Freq = .N), by=list(LoanID, Date)][Freq>1, .N]
cat( (check_input1a == 0) %?% 'SAFE: Grain of {datInput.rawdatInput.raw} confirmed.\n' %:%
paste0('WARNING: Grain broken in {datInput.raw} for ', check_input2a, " cases.\n") )
datCredit_smp[is.na(LoanID),.N]
datCredit_smp[is.na(Date),.N]
datInput.raw[is.na(LoanID),.N]
datInput.raw[is.na(Date),.N]
check_input2a
datInput.raw[, list(Freq = .N), by=list(LoanID, Date)][Freq>1, LoanID]
# - [SANITY CHECK] Check the data grain
check_input2a <- datInput.raw[, list(Freq = .N), by=list(LoanID, Date)][Freq>1, .N]
cat( (check_input1a == 0) %?% 'SAFE: Grain of {datInput.rawdatInput.raw} confirmed.\n' %:%
paste0('WARNING: Grain broken in {datInput.raw} for ', check_input2a, " cases.\n") )
# - Merge on LoanID and Date by performing a left-join
datCredit_smp <- merge(datCredit_smp, datInput.raw, by=c("Date", "LoanID"), all.x=T); gc()
cat( (check_input2a == 0) %?% 'SAFE: Grain of {datInput.rawdatInput.raw} confirmed.\n' %:%
paste0('WARNING: Grain broken in {datInput.raw} for ', check_input2a, " cases.\n") )
# [SANITY CHECK] Confirm dataset's grain after fusion
check_input2b <- datCredit_smp[,list(Freqs = .N), by=list(LoanID, Date)][Freqs > 1,.N]
cat( (check_input2b == 0) %?% 'SAFE: Grain of {datCredit_smp} confirmed after fusion.\n' %:%
paste0('ERROR: Grain broken in {datCredit_smp} after fusion for ', check_input2b, " cases.\n") )
# - Save to disk (zip) for quick disk-based retrieval later
pack.ffdf(paste0(genPath, "creditdata_final4c"), datCredit_smp); gc()
# - Clean-up
rm(datInput.raw, data_grain_check); gc()
# - Clean-up
rm(datInput.raw, check_input1a); gc()
# - Clean-up
rm(datInput.raw, check_input1, check_input2a, check_input2b); gc()
# - Load in main dataset (subsampled)
if (!exists('datCredit_smp')) unpack.ffdf(paste0(genPath,"creditdata_final4c"), tempPath)
# --- 1. Missing value indicators for the input space variables
# NOTE: There are a lot of missing values for these variables because of system changes etc.
datCredit_smp[, value_ind_slc_pmnt_method := ifelse(is.na(slc_pmnt_method) | slc_pmnt_method == "", 1, 0)]
datCredit_smp[, value_ind_slc_days_excess := ifelse(is.na(slc_days_excess) | slc_days_excess == "", 1, 0)]
datCredit_smp[, value_ind_slc_acct_pre_lim_perc := ifelse(is.na(slc_acct_pre_lim_perc) | slc_acct_pre_lim_perc == "", 1, 0)]
datCredit_smp[, value_ind_slc_acct_roll_ever_24 := ifelse(is.na(slc_acct_roll_ever_24) | slc_acct_roll_ever_24 == "", 1, 0)]
datCredit_smp[, value_ind_slc_acct_arr_dir_3 := ifelse(is.na(slc_acct_arr_dir_3) | slc_acct_arr_dir_3 == "", 1, 0)]
datCredit_smp[, value_ind_slc_acct_prepaid_perc_dir_12 := ifelse(is.na(slc_acct_prepaid_perc_dir_12) | slc_acct_prepaid_perc_dir_12 == "", 1, 0)]
# - Check the missingness of the variables
# If they are more than 50% missing - remove
table(datCredit_smp$value_ind_slc_pmnt_method) %>% prop.table()              # missingness: 10.78% - keep the variable (categorical)
table(datCredit_smp$value_ind_slc_days_excess) %>% prop.table()              # missingness: 74.09% - discard the variable
table(datCredit_smp$value_ind_slc_acct_pre_lim_perc) %>% prop.table()        # missingness: 10.78% - keep the variable (numeric)
table(datCredit_smp$value_ind_slc_acct_roll_ever_24) %>% prop.table()        # missingness: 10.79% - keep the variable (numeric + delinquency theme)
table(datCredit_smp$value_ind_slc_acct_arr_dir_3) %>% prop.table()           # missingness: 10.78% - keep the variable (categorical + delinquency theme)
table(datCredit_smp$value_ind_slc_acct_prepaid_perc_dir_12) %>% prop.table() # missingness: 10.78% - keep the variable (numeric)
# - Remove the variables that have missingness > 50%
suppressWarnings( datCredit_smp[, `:=`(value_ind_slc_days_excess = NULL, slc_days_excess = NULL)]); gc()
# --- 2. Basic statistics of each variable
# - Categorical variables
varList_Cat <- c('slc_pmnt_method','slc_acct_arr_dir_3',
'g0_Delinq','DefaultStatus1', 'DefaultStatus1_lead_12_max',
'PerfSpellResol_Type_Hist','HasLeftTruncPerfSpell',
'DefSpellResol_Type_Hist','HasLeftTruncDefSpell',
'Event_Type', 'Redraw_Ind','g0_Delinq_Shift')
var_Info_Cat <- describe(subset(datCredit_smp, select = varList_SLC_Cat))
var_Info_Cat <- describe(subset(datCredit_smp, select = varList_Cat))
# --- 2. Basic statistics of each variable
# - Categorical variables
varList_Cat <- c('slc_pmnt_method','slc_acct_arr_dir_3',
'g0_Delinq','DefaultStatus1', 'DefaultStatus1_lead_12_max',
'PerfSpellResol_Type_Hist','HasLeftTruncPerfSpell',
'DefSpellResol_Type_Hist','HasLeftTruncDefSpell',
'Event_Type','g0_Delinq_Shift')
var_Info_Cat <- describe(subset(datCredit_smp, select = varList_Cat))
varCredit_Info_Cat
varCredit_Info_Cat <- describe(subset(datCredit_smp, select = varList_Credit_Cat))
varCredit_Info_Cat <- describe(subset(datCredit_smp, select = varList_Credit_Cat))
# ------- 6. Feature engineering for modelling purposes (Credit data input space)
# --- Computing basic statistics of each variable
# - Categorical variables
varList_Credit_Cat <- c('g0_Delinq','DefaultStatus1', 'DefaultStatus1_lead_12', 'DefaultStatus1_lead_12_max',
'PerfSpell_LeftTrunc', 'PerfSpellResol_Type_Hist','HasLeftTruncPerfSpell',
'DefSpell_LeftTrunc', 'DefSpellResol_Type_Hist','HasLeftTruncDefSpell',
'Event_Type','WOff_Ind',
'EarlySettle_Ind','FurtherLoan_Ind','Redraw_Ind','LN_TPE','Repaid_Ind',
'g0_Delinq_Shift', 'PerfSpell_g0_Delinq_Shift', 'DefSpell_g0_Delinq_Shift')
varCredit_Info_Cat <- describe(subset(datCredit_smp, select = varList_Credit_Cat))
# --- 2. Basic statistics of each variable
# - Categorical variables
varList_Cat <- c('slc_pmnt_method','slc_acct_arr_dir_3',
'g0_Delinq','DefaultStatus1', 'DefaultStatus1_lead_12_max',
'PerfSpellResol_Type_Hist','HasLeftTruncPerfSpell',
'DefSpellResol_Type_Hist','HasLeftTruncDefSpell',
'Event_Type','g0_Delinq_Shift')
var_Info_Cat <- describe(subset(datCredit_smp, select = varList_Cat))
# - Numeric variables
varList_SLC_Num <- c('slc_past_due_amt','slc_acct_pre_lim_perc','slc_acct_prepaid_perc_dir_12','slc_acct_roll_ever_24',
'Age_Adj', 'PerfSpell_Num','Term','InterestRate_Nom','InterestRate_Margin','Principal','Instalment','Receipt_Inf','Arrears',
'Balance','TimeInPerfSpell','PerfSpell_Age', 'PerfSpell_Counter',
'TimeInDefSpell', 'DefSpell_Age', 'DefSpell_Counter',
'Event_Time', 'g0_Delinq_Num', 'g0_Delinq_SD')
varSLC_Info_Num <- describe(subset(datCredit_smp, select = varList_SLC_Num))
# - Numeric variables
varList_Num <- c('slc_past_due_amt','slc_acct_pre_lim_perc','slc_acct_prepaid_perc_dir_12','slc_acct_roll_ever_24',
'Age_Adj', 'PerfSpell_Num','Term','InterestRate_Nom','InterestRate_Margin','Principal','Instalment','Receipt_Inf','Arrears',
'Balance','TimeInPerfSpell','PerfSpell_Age', 'PerfSpell_Counter',
'TimeInDefSpell', 'DefSpell_Age', 'DefSpell_Counter',
'Event_Time', 'g0_Delinq_Num', 'g0_Delinq_SD')
rm(varSLC_Info_Num)
# - Numeric variables
varList_Num <- c('slc_past_due_amt','slc_acct_pre_lim_perc','slc_acct_prepaid_perc_dir_12','slc_acct_roll_ever_24',
'Age_Adj', 'PerfSpell_Num','Term','InterestRate_Nom','InterestRate_Margin','Principal','Instalment','Receipt_Inf','Arrears',
'Balance','TimeInPerfSpell','PerfSpell_Age', 'PerfSpell_Counter',
'TimeInDefSpell', 'DefSpell_Age', 'DefSpell_Counter',
'Event_Time', 'g0_Delinq_Num', 'g0_Delinq_SD')
var_Info_Num <- describe(subset(datCredit_smp, select = varList_Num))
var_Info_Num
# - Payment method
var_Info_Cat$slc_pmnt_method
# Merge with existing "Unknown" bin or empty values
datCredit_smp[, slc_pmnt_method :=
ifelse(is.na(slc_pmnt_method) | slc_pmnt_method == "" | slc_pmnt_method == "Unknown",
"MISSING_DATA", slc_pmnt_method)]
# [SANITY CHECK] Confirm treatment success
cat( (sum(datCredit_smp$slc_pmnt_method == "" | is.na(datCredit_smp$slc_pmnt_method) |
datCredit_smp$slc_pmnt_method == "Unknown") == 0) %?%
'SAFE: Treatment successful for [slc_pmnt_method].\n' %:% 'ERROR: Treatment failed for [slc_pmnt_method] \n' )
(var_Info_Cat$slc_pmnt_method <- describe(datCredit_smp$slc_pmnt_method))
# - Account-level arrears direction vs three months ago
var_Info_Cat$slc_acct_arr_dir_3
# Merge with existing "N/A" bin or empty values
datCredit_smp[, slc_acct_arr_dir_3 :=
ifelse(is.na(slc_acct_arr_dir_3) | slc_acct_arr_dir_3 == "" | slc_acct_arr_dir_3 == "N/A",
"MISSING_DATA", slc_acct_arr_dir_3)]
# [SANITY CHECK] Confirm treatment success
cat( ( sum(datCredit_smp$slc_acct_arr_dir_3 == "" | is.na(datCredit_smp$slc_acct_arr_dir_3) |
datCredit_smp$slc_acct_arr_dir_3 == "N/A") == 0) %?%
'SAFE: Treatment successful for [slc_acct_arr_dir_3].\n' %:% 'ERROR: Treatment failed for [slc_acct_arr_dir_3] \n' )
(var_Info_Cat$slc_acct_arr_dir_3 <- describe(datCredit_smp$slc_acct_arr_dir_3))
# - Prepaid/available funds to limit
var_Info_Num$slc_acct_pre_lim_perc; hist(datCredit_smp$slc_acct_pre_lim_perc, breaks='FD')
datCredit_smp[is.na(slc_acct_pre_lim_perc), .N] / datCredit_smp[,.N] * 100
### RESULTS: Highly right-skewed distribution, with mean of ~0.09 vs median of 0,
# bounded by [0, 0.79] for 5%-95% percentiles; no outliers
# Use median imputation, given 10.78% missingness degree, trading off the minor distributional distortion as a result
datCredit_smp[, slc_acct_pre_lim_perc_imputed :=
ifelse(is.na(slc_acct_pre_lim_perc) | slc_acct_pre_lim_perc == "",
median(slc_acct_pre_lim_perc, na.rm=TRUE), slc_acct_pre_lim_perc)]
# [SANITY CHECK] Confirm treatment success
cat( ( datCredit_smp[is.na(slc_acct_pre_lim_perc_imputed), .N ] == 0) %?%
'SAFE: Treatment successful for [slc_acct_pre_lim_perc_imputed].\n' %:%
'ERROR: Treatment failed for [slc_acct_pre_lim_perc_imputed] \n' )
(var_Infro_Num$slc_acct_pre_lim_perc <- describe(datCredit_smp$slc_acct_pre_lim_perc_imputed)); hist(datCredit_smp$slc_acct_pre_lim_perc_imputed, breaks='FD')
(var_Info_Num$slc_acct_pre_lim_perc <- describe(datCredit_smp$slc_acct_pre_lim_perc_imputed)); hist(datCredit_smp$slc_acct_pre_lim_perc_imputed, breaks='FD')
# - Number of times an account was in arrears over last 24 months
var_Info_Num$slc_acct_roll_ever_24; hist(datCredit_smp$slc_acct_roll_ever_24, breaks='FD')
datCredit_smp[is.na(slc_acct_roll_ever_24), .N] / datCredit_smp[,.N] * 100
### RESULTS: Highly right-skewed distribution with mean of 0.4871, though discrete values with 80% of data having 0-value.
# Use mean imputation, given 10.79% missingness degree, trading off the minor distributional distortion as a result
datCredit_smp[, slc_acct_roll_ever_24_imputed :=
ifelse(is.na(slc_acct_roll_ever_24) | slc_acct_roll_ever_24 == "",
mean(slc_acct_roll_ever_24, na.rm=TRUE), slc_acct_roll_ever_24)]
# [SANITY CHECK] Confirm treatment success
cat( ( datCredit_smp[is.na(slc_acct_roll_ever_24_imputed), .N ] == 0) %?%
'SAFE: Treatment successful for [slc_acct_roll_ever_24_imputed].\n' %:%
'ERROR: Treatment failed for [slc_acct_roll_ever_24_imputed] \n' )
hist(datCredit_smp$slc_acct_roll_ever_24_imputed)
hist(datCredit_smp$slc_acct_roll_ever_24_imputed, breaks='FD')
# - Numeric variables
varList_Num <- c('slc_past_due_amt','slc_acct_pre_lim_perc','slc_acct_prepaid_perc_dir_12','slc_acct_roll_ever_24',
'Age_Adj', 'PerfSpell_Num','Term','InterestRate_Nom','InterestRate_Margin','Principal','Instalment','Receipt_Inf','Arrears',
'Balance','TimeInPerfSpell','PerfSpell_Age', 'PerfSpell_Counter',
'TimeInDefSpell', 'DefSpell_Age', 'DefSpell_Counter',
'Event_Time', 'g0_Delinq_Num', 'g0_Delinq_SD')
var_Info_Num <- describe(subset(datCredit_smp, select = varList_Num))
# - Prepaid/available funds to limit
var_Info_Num$slc_acct_pre_lim_perc; hist(datCredit_smp$slc_acct_pre_lim_perc, breaks='FD')
datCredit_smp[is.na(slc_acct_pre_lim_perc), .N] / datCredit_smp[,.N] * 100
### RESULTS: Highly right-skewed distribution, with mean of ~0.09 vs median of 0,
# bounded by [0, 0.79] for 5%-95% percentiles; no outliers
# Use median imputation, given 10.78% missingness degree, trading off the minor distributional distortion as a result
datCredit_smp[, slc_acct_pre_lim_perc_imputed :=
ifelse(is.na(slc_acct_pre_lim_perc) | slc_acct_pre_lim_perc == "",
median(slc_acct_pre_lim_perc, na.rm=TRUE), slc_acct_pre_lim_perc)]
# [SANITY CHECK] Confirm treatment success
cat( ( datCredit_smp[is.na(slc_acct_pre_lim_perc_imputed), .N ] == 0) %?%
'SAFE: Treatment successful for [slc_acct_pre_lim_perc_imputed].\n' %:%
'ERROR: Treatment failed for [slc_acct_pre_lim_perc_imputed] \n' )
(var_Info_Num$slc_acct_pre_lim_perc_imputed <- describe(datCredit_smp$slc_acct_pre_lim_perc_imputed)); hist(datCredit_smp$slc_acct_pre_lim_perc_imputed, breaks='FD')
# - Percentage-valued direction of prepaid/available funds - current compared to 12 months ago
describe(datCredit_smp$slc_acct_prepaid_perc_dir_12); hist(datCredit_smp[slc_acct_prepaid_perc_dir_12<=5, slc_acct_prepaid_perc_dir_12])
datCredit_smp[is.na(slc_acct_prepaid_perc_dir_12), .N] / datCredit_smp[,.N] * 100
### RESULTS: Highly right-skewed distribution, with mean of ~1.6m vs median of 0,
# bounded by [0, 3.34] for 5%-95% percentiles; some very large outliers
### AB: Scope for extreme value treatment if those outliers are correct; or use winsorized mean (Std-PrinciplesForDataPrep)
# Use median imputation, given 10.78% missingness degree, trading off the minor distributional distortion as a result
datCredit_smp[, slc_acct_prepaid_perc_dir_12_imputed :=
ifelse(is.na(slc_acct_prepaid_perc_dir_12) | slc_acct_prepaid_perc_dir_12 == "",
median(slc_acct_prepaid_perc_dir_12, na.rm=TRUE), slc_acct_prepaid_perc_dir_12)]
# [SANITY CHECK] Confirm treatment success
cat( ( datCredit_smp[is.na(slc_acct_prepaid_perc_dir_12_imputed), .N] == 0) %?%
'SAFE: Treatment successful for [slc_acct_prepaid_perc_dir_12_imputed].\n' %:%
'ERROR: Treatment failed for [slc_acct_prepaid_perc_dir_12_imputed] \n' )
describe(datCredit_smp$slc_acct_prepaid_perc_dir_12_imputed); hist(datCredit_smp[slc_acct_prepaid_perc_dir_12_imputed<=5, slc_acct_prepaid_perc_dir_12_imputed])
# - InterestRate_Margin (incorporating risk-based pricing info)
var_Info_Num$InterestRate_Margin; hist(datCredit_smp$InterestRate_Margin, breaks="FD")
datCredit_smp[is.na(InterestRate_Margin), .N] / datCredit_smp[,.N] * 100
### RESULTS: Highly right-skewed distribution (as expected), with mean of -0.007 vs median of -0.008,
# bounded by [-0.02, 0.01] for 5%-95% percentiles; some negative outliers distort shape of distribution
# Use median imputation, given 0.46% missingness degree
datCredit_smp[, InterestRate_Margin_imputed :=
ifelse(is.na(InterestRate_Margin) | InterestRate_Margin == "",
median(InterestRate_Margin, na.rm=TRUE), InterestRate_Margin)]
# [SANITY CHECK] Confirm treatment success
cat( ( datCredit_smp[is.na(InterestRate_Margin_imputed), .N] == 0) %?%
'SAFE: Treatment successful for [InterestRate_Margin_imputed].\n' %:%
'ERROR: Treatment failed for [InterestRate_Margin_imputed] \n' )
(var_Info_Num$InterestRate_Margin_Imputed <- describe(datCredit_smp$InterestRate_Margin_imputed)); hist(datCredit_smp$InterestRate_Margin_imputed, breaks="FD")
var_Info_Num$InterestRate_Nom
# - Loan age to loan term
datCredit_smp[, AgeToTerm := Age_Adj/Term] # where the loan is in its lifetime
# [SANITY CHECK] Check new feature for illogical values
cat( ( datCredit_smp[is.na(AgeToTerm), .N] == 0) %?%
'SAFE: New feature [AgeToTerm] has logical values.\n' %:%
'WARNING: New feature [AgeToTerm] has illogical values \n' )
(var_Info_Num$AgeToTerm <- describe(datCredit_smp$AgeToTerm)); hist(datCredit_smp[AgeToTerm<2, AgeToTerm])
# - Balance to loan term | how much is still outstanding compared to Principal/Limit
datCredit_smp[, BalanceToPrincipal := Balance/Principal]
# [SANITY CHECK] Check new feature for illogical values
cat( ( datCredit_smp[is.na(BalanceToPrincipal), .N] == 0) %?%
'SAFE: New feature [BalanceToPrincipal] has logical values.\n' %:%
'WARNING: New feature [BalanceToPrincipal] has illogical values \n' )
(var_Info_Num$AgeToTerm <- describe(datCredit_smp$AgeToTerm)); hist(datCredit_smp[AgeToTerm<2, AgeToTerm], breaks='FD')
# - Balance to loan term | how much is still outstanding compared to Principal/Limit
datCredit_smp[, BalanceToPrincipal := Balance/Principal]
# [SANITY CHECK] Check new feature for illogical values
cat( ( datCredit_smp[is.na(BalanceToPrincipal), .N] == 0) %?%
'SAFE: New feature [BalanceToPrincipal] has logical values.\n' %:%
'WARNING: New feature [BalanceToPrincipal] has illogical values \n' )
# distributional analysis
(var_Info_Num$BalanceToTerm <- describe(datCredit_smp$BalanceToPrincipal)); hist(datCredit_smp$BalanceToPrincipal, breaks='FD')
# - Condense the payment group
datCredit_smp[, pmnt_method_grp :=
case_when(slc_pmnt_method == "Debit Order FNB account" | slc_pmnt_method == "Debit Order other bank" ~ "Debit Order",
slc_pmnt_method == "Salary" | slc_pmnt_method == "Suspense" ~ "Salary/Suspense",
TRUE ~ slc_pmnt_method)]
# [SANITY CHECK] Check new feature for illogical values
cat( ( datCredit_smp[is.na(pmnt_method_grp), .N] == 0) %?%
'SAFE: New feature [pmnt_method_grp] has logical values.\n' %:%
'WARNING: New feature [pmnt_method_grp] has illogical values \n' )
(var_Info_Cat$pmnt_method_grp <- describe(datCredit_smp$pmnt_method_grp))
# - Log-transform of Balance
var_Info_Num$Balance; hist(datCredit_smp$Balance, breaks="FD")
log(1)
datCredit_smp[, BalanceLog := ifelse(Balance > 0, log(Balance), log(1))]
# [SANITY CHECK] Check new feature for illogical values
cat( ( datCredit_smp[is.na(BalanceLog), .N] == 0) %?%
'SAFE: New feature [BalanceLog] has logical values.\n' %:%
'WARNING: New feature [BalanceLog] has illogical values \n' )
(var_Info_Num$Balance <- describe(datCredit_smp$BalanceLog)); hist(datCredit_smp$BalanceLog, breaks="FD")
y <- seq(-4, 4, len = (nn <- 200))
ltry <- c(0, 0.5, 1, 1.5, 2)  # Try these values of lambda
lltry <- length(ltry)
psi <- matrix(NA_real_, nn, lltry)
for (ii in 1:lltry)
psi[, ii] <- yeo.johnson(y, lambda = ltry[ii])
# ------ 5. Apply basic cross-validation resampling scheme with 2-way stratified sampling
datCredit_smp[, Ind := 1:.N] # prepare for resampling scheme
# - Implement resampling scheme using given main sampling fraction
set.seed(1)
datCredit_train <- datCredit_smp %>% group_by(across(all_of(stratifiers))) %>% slice_sample(prop=train_prop) %>% as.data.table()
datCredit_valid <- subset(datCredit_smp, !(Ind %in% datCredit_train$Ind)) %>% as.data.table()
# - Save to disk (zip) for quick disk-based retrieval later
pack.ffdf(paste0(genPath, "creditdata_train"), datCredit_train); gc()
pack.ffdf(paste0(genPath, "creditdata_valid"), datCredit_valid); gc()
genObjPath
# --- Save "description" objects to disk
pack.ffdf(paste0(genObjPath, "var_Info_Cat"), var_Info_Cat)
pack.ffdf(paste0(genObjPath, "var_Info_Num"), var_Info_Num)
# --- Clean up
rm(varList_Cat, varList_Num, var_Info_Cat, var_Info_Num, datExcl, datExclusions,
stratifiers, smp_perc, smp_size, targetVar, timeVar, train_prop, overlap_flds)
rm(list=ls())
# =================================== SETUP =============================================
# Setting up R environment, parameters, and function definitions
# ---------------------------------------------------------------------------------------
# PROJECT TITLE: Classifier Diagnostics
# SCRIPT AUTHOR(S): Dr Arno Botha, Roelinde Bester
# DESCRIPTION:
# This script installs and loads various libraries and packages, compiles all
# custom functions, and set requisite parameters.
# ---------------------------------------------------------------------------------------
# -- Inputs:
#   - DelinqM.R | Delinquency measures and related functions
# =======================================================================================
# ================ 0. Library setup
# ------ Install and load packages
# - data access and big data management
require(haven) # for SAS imports
require(ETLUtils)
require(ffbase)
require(ff)
tempPath <- "C:/TempData"; options("fftempdir"=tempPath)
# for data wrangling
require(tidyr)
require(dplyr)
require(data.table)
require(lubridate)
require(readr)
require(bit64) # for very big numeric values
require(foreach); require(doParallel) # for multi-threaded computing
require(stringr) # common string operations, e.g, str_pad
require(purrr) # mapping functions from tidyverse in working with matrices, lists
require(writexl) #for exporting to Excel
require(zoo)
# for analyses & modelling
require(Hmisc)
require(survival) # for survival modelling
require(pROC); require(ROCR) # both for conducting ROC-analyses
#for plots
require(ggplot2)
require(scales)
require(ggthemes)
require(ggpp) # Extensions to ggplot2, particularly geom_table
require(RColorBrewer)
require(extrafont) #remotes::install_version("Rttf2pt1", version = "1.3.8"); Sys.setenv(R_GSCMD="C:/Program Files/gs/gs9.55.0/bin/gswin32c.exe"); font_import(); loadfonts(); loadfonts(device="win")
require(survminer)
require(gridExtra)
# require(runner) # Unsure of this, marked for deletion
# ================ 1. Parametrisation
# - general R options
options(scipen=999) # Suppress showing scientific notation
# - Parameters used in calculating delinquency measures
sc.Thres <- 0.9; # repayment ratio - g1
d <- 3 # default threshold for g0/g1-measures of delinquency (payments in arrears)
k <- 6 # Probation period
# -- Path variables | General
# - Common path for saving big data objects
genPath <- "C:/Data/Classifier-Diagnostics_Data/"
# - Common path for importing raw data
genRawPath <- "C:/Data/"
# -- Path variables | User-dependent
if (Sys.getenv("USERNAME") == "WRQ") {
# - Custom path where R-scripts are saved
path_cust <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Classifier-Diagnostics/Scripts/"
# - Common path for storing important R-objects as back-up
genObjPath <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Classifier-Diagnostics/Objects/"
# - Common path for saving important analytics (e.g., sampling)
genFigPath <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Classifier-Diagnostics/Figures/"
} else if (Sys.getenv("USERNAME") == "Arno Botha") {
# - Custom path where R-scripts are saved
path_cust <- "E:/WorkLife/Analytix/Research/Classifier-Diagnostics/Scripts/"
# - Common path for storing important R-objects as back-up
genObjPath <- "E:/WorkLife/Analytix/Research/Classifier-Diagnostics/Objects/"
# - Common path for saving important analytics (e.g., sampling)
genFigPath <- "E:/WorkLife/Analytix/Research/Classifier-Diagnostics/Figures/"
# - Common path for saving big data objects
genPath <- "E:/DataDump/FNB SLC/Classifier-Diagnostics_Data/"
# - Common path for importing raw data
genRawPath <- "E:/DataDump/FNB SLC/"
} else if (Sys.getenv("USERNAME") == "R5532132") {
# - Custom path where R-scripts are saved
path_cust <- "C:/Users/R5532132/OneDrive - FRG/Classifier-Diagnostics/Scripts/"
# - Common path for storing important R-objects as back-up
genObjPath <- "C:/Users/R5532132/OneDrive - FRG/Classifier-Diagnostics/Objects/"
# - Common path for saving important analytics (e.g., sampling)
genFigPath <- "C:/Users/R5532132/OneDrive - FRG/Classifier-Diagnostics/Figures/"
}  else {
stop("User-specific paths not set for current user: ", Sys.getenv("USERNAME"), ". Please fix in Setup script (0.Setup.R) before continuing")
}
# ================ 2. Custom functions
# ------ Custom function definitions
# - Load all custom functions defined in a separate R-script
source(paste0(path_cust,"0a.CustomFunctions.R"))
# - Compile Delinquency Calculation Functions (CD, MD/DoD)
source(paste0(path_cust,'DelinqM.R'))
# - Compile the TruEnd-suite of evaluation (and auxiliary) functions
source(paste0(path_cust,'TruEnd.R'))
ptm <- proc.time() # for runtime calculations (ignore)
# - Confirm prepared datasets are loaded into memory
if (!exists('datCredit_train')) unpack.ffdf(paste0(genPath,"creditdata_train"), tempPath)
if (!exists('datCredit_valid')) unpack.ffdf(paste0(genPath,"creditdata_valid"), tempPath)
# ------ 2. Modelling & Feature Selection by theme
###### TEST ######
logitMod_Test_Bal <- glm(inputs_Test_Bal <- DefaultStatus1_lead_12_max ~ Balance,
data=datCredit_valid, family="binomial")
summary(logitMod_Test_Bal)
# --- Transformed variable
logitMod_Test_log_Bal <- glm(inputs_Test_Bal <- DefaultStatus1_lead_12_max ~ BalanceLog,
data=datCredit_valid, family="binomial")
# - Model assessment
summary(logitMod_Test_log_Bal)
### RESULTS: Null deviance = 252730; Residual deviance = 25606; AIC = 252610
# ROC analysis
datCredit_valid[, prob_Test_Bal := predict(logitMod_Test_Bal, newdata = datCredit_valid, type="response")]
auc(datCredit_valid$DefaultStatus1_lead_12_max, datCredit_valid$prob_Test_Bal) # 60.53%
### RESULTS: Null deviance = 252730; Residual deviance = 252240; AIC = 252244
datCredit_valid[, prob_Test_log_Bal := predict(logitMod_Test_log_Bal, newdata = datCredit_valid, type="response")]
auc(datCredit_valid$DefaultStatus1_lead_12_max, datCredit_valid$prob_Test_log_Bal)
cbind(OR = coef(logitMod_Test_log_Bal), confint.default(logitMod_Test_log_Bal))
# Oddr ration analysis
round(exp(cbind(OR = coef(logitMod_Test_log_Bal), confint.default(logitMod_Test_log_Bal))), 3)
### RESULTS: Null deviance = 252730; Residual deviance = 25606; AIC = 252610
# Odds ration analysis
round(exp(cbind(OR = coef(logitMod_Test_Bal), confint.default(logitMod_Test_Bal))), 3)
rm9list=ls()
rm(list=ls()
)
